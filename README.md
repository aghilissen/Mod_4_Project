# Mod_4_Project


> ## The CRISP-DM Framework
> 
> - Business Problem: Reduce Motor Vehicle Deaths in the US using Socio Economic Data
> - Data Understanding: What the data set is
> - Data Preparation: All Data Cleaning, inc treatment of missing Data, NaNs, zeros, transforms
> - Modelling: The Modelling Workflow, models used and feature transforms / engineering
> - Evaluation: Evaluation of the Final Model vs Baseline Model
> - Deployment: Results generated by the model

## Business Problem

Identify Factors that could help Reduce Motor Vehicle Deaths in the US using Socio Economic Data.

## Data Understanding

The dataset is a collaboration between the Robert Wood Johnson Foundation and the University of Wisconsin Population Health Institute using the 2019 County Health Ratings, which includes the following Socio Economic Data and Indicators:

  - Child mortality
  - Children eligible for free or reduced price lunch
  - Demographics
  - Diabetes prevalence
  - Disconnected youth
  - Drug overdose deaths
  - Firearm fatalities
  - Food insecurity
  - Frequent mental distress
  - Frequent physical distress
  - HIV prevalence
  - Home ownership
  - Homicides
  - Infant mortality
  - Insufficient sleep
  - Life expectancy
  - Limited access to healthy foods
  - Median household income
  - **Motor vehicle crash deaths**
  - Other primary care providers
  - Premature age-adjusted mortality
  - Residential segregation
  - Severe housing cost burden
  - Uninsured adults
  - Uninsured children

## Data Preparation

All merging, cleaning, transformations involved in the preprocessing stage. The [DataPreparation](./DataPreparation.ipynb) notebook details the steps of this process, and contains the python code used during that step.

## Modelling

After taking into account various factors (variance inflation factor, multicollinearity and intuition), we have managed to narrow down the amount of features used in our model to 10 features:
- % Physically Inactive
- % Excessive Drinking
- % Alcohol Impaired
- % Uninsured
- % Long Commute - Drives Alone
- Household Income
- Population
- % under 18
- % 65 and over
- % Rural

The baseline model used a simple linear regression without transforming any data (besides the scaling step) and showed an accuracy of about 50%. In order to increase the accuracy, the final (selected) model used a cubic polynomial transformation and it was penalised with a LASSO (least absolute shrinkage and selection operator) method. This combination allowed the accuracy to go up to 56%. Considering our third degree polynomial and the feature expansion subsequent to this transformation, we decided to sacrifice the few extra percent of accuracy offered by an ElasticNet penalisation method for the feature slayer: LASSO.

At the end of the regularisation/penalisation process, we were left with 51 features and interactions.

## Evaluation

After selecting our model, we ran the model on the test dataset and it showed similar performances (slightly better actually), meaning that this model, although not hugely accurate, is robust.

The analysis of the residuals showed that the data is heteroscedatic and biased. This is mainly due to the features selected. A finer tuning of feature selection process would improve the model significantly but we strongly believe interpretability would be handicapped by such a move.

## Deployment

Refer to the [Presentation](./presentation.pdf) slides for a detailed view of our findings.

__Note__

If you feel the need for more details, the [index](./index.ipynb) contains our statistical 
analysis as well as all our code.
_Work by Pete and Antoine_